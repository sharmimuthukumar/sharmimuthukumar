import pandas as pd import numpy as np import matplotlib.pyplot as plt from sklearn.model_selection import train_test_split, cross_val_score from sklearn.feature_extraction.text import TfidfVectorizer from sklearn.linear_model import LogisticRegression from sklearn.naive_bayes import MultinomialNB from sklearn.svm import SVC from sklearn.ensemble import VotingClassifier from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, roc_curve, auc import joblib from fpdf import FPDF

Step 1: Load the dataset

try: df = pd.read_csv('news.csv')  # Replace with your dataset path print("Dataset loaded successfully!") except Exception as e: print(f"Error loading dataset: {e}")

Step 2: Data Preprocessing

print("Data Preprocessing...") df = df.dropna() X = df['text'] y = df['label']

Step 3: Data Augmentation (if required)

print("Data Augmentation...") if df['label'].value_counts().min() < 1000: minority_class = df['label'].value_counts().idxmin() minority_df = df[df['label'] == minority_class] augmented_df = minority_df.sample(1000, replace=True) df = pd.concat([df, augmented_df])

Split the dataset

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

Step 4: Feature Extraction using TF-IDF

print("Feature Extraction...") tfidf = TfidfVectorizer(stop_words='english', max_df=0.7) X_train_tfidf = tfidf.fit_transform(X_train) X_test_tfidf = tfidf.transform(X_test)

Step 5: Train Multiple Models

print("Training models...") models = { "Logistic Regression": LogisticRegression(), "Naive Bayes": MultinomialNB(), "SVM": SVC(probability=True) }

for name, model in models.items(): model.fit(X_train_tfidf, y_train) score = cross_val_score(model, X_train_tfidf, y_train, cv=5).mean() print(f"{name} cross-validation score: {score:.4f}")

Ensemble Model

ensemble = VotingClassifier(estimators=[(n, m) for n, m in models.items()], voting='soft') ensemble.fit(X_train_tfidf, y_train)

Step 6: Evaluation

print("Evaluating the ensemble model...") y_pred = ensemble.predict(X_test_tfidf) accuracy = accuracy_score(y_test, y_pred) report = classification_report(y_test, y_pred)

PDF Report Generation

pdf = FPDF() pdf.add_page() pdf.set_font("Arial", size=12) pdf.cell(200, 10, txt="Fake News Detection Report", ln=True, align='C') pdf.cell(200, 10, txt=f"Accuracy: {accuracy:.4f}", ln=True) pdf.multi_cell(0, 10, txt=f"Classification Report:\n{report}") pdf.output("Fake_News_Report.pdf") print("PDF Report saved as Fake_News_Report.pdf")

Confusion Matrix

conf_matrix = confusion_matrix(y_test, y_pred) plt.figure(figsize=(6, 6)) plt.title("Confusion Matrix") plt.imshow(conf_matrix, cmap='Blues') plt.xlabel("Predicted") plt.ylabel("Actual") plt.savefig("confusion_matrix.png") plt.show()

ROC Curve

fpr, tpr, _ = roc_curve(y_test, ensemble.predict_proba(X_test_tfidf)[:, 1]) roc_auc = auc(fpr, tpr) plt.figure() plt.plot(fpr, tpr, label=f'ROC Curve (area = {roc_auc:.2f})') plt.xlabel("False Positive Rate") plt.ylabel("True Positive Rate") plt.title("Receiver Operating Characteristic") plt.savefig("roc_curve.png") plt.show()

Save the best model

joblib.dump(ensemble, "best_fake_news_detector.pkl") print("Best model saved!")

Predicting new data

def predict_news(text): text_tfidf = tfidf.transform([text]) prediction = ensemble.predict(text_tfidf) return "Fake" if prediction == 1 else "Real"

print("Advanced model with PDF report ready for fake news d
